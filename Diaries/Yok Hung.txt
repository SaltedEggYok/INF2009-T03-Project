23/2/2024
Found a speech emotion recognition model at https://github.com/MiteshPuthran/Speech-Emotion-Analyzer
Tested their inpyb file locally on my laptop and was able to get things working
This model is a CNN, and has already been trained with multiple layers

26/2/2024
Found another model at https://github.com/MeidanGR/SpeechEmotionRecognition_Realtime/tree/main
Their model is a LSTM instead, but it is real time, instead of reading a file directly
Might be useful if we want to do real-time analysis, will keep it in consideration
Notably higher accuracy compared to the other one previously found

28/2/2024
Tested 1st model's prediction on the Raspberry Pi, seems to be able to work fine
Able to take in recorded audio and have a result appear  

13/3/2024
Tested 2nd model's runtime and prediction, works fine. However as we have changed the structure of program,
the 1st model seems to be more suitable for our needs. Thus will continue working on taking and adapting the 1st
model into our application.

20/3/2024
Made the main loop of the SER system, able to run until stopping, reccording audio in 4 second bursts, and predicting on them

27/3/2024
Processed output of the model, and output everything to text files, following FER's format, to allow for easier intergration with GUI

4/4/2024
Retrained model with our dataset

6/4/2024
Intergrated MQTT into the system
